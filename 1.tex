\documentclass[11pt]{beamer}
\usetheme{CambridgeUS}
\usepackage[utf8]{inputenc}
\usepackage[icelandic]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{N PRAFUL RAJ}
\title{Speech Recognition Project}
\institute[IIT-H]
{
\\Guided by:\\Dr G.V.V.Sharma
}
\setbeamercovered{transparent} 

\setbeamertemplate{navigation symbols}{} 
\logo{\includegraphics[height=1.5cm]{logo.jpg}} 

\date{12-10-2020} 
\subject{EE5600/AI5600} 
\begin{document}


\begin{frame}
\titlepage
\end{frame}



\begin{frame}
\frametitle{Introduction}
Training the machine Learning Algorithm Left,Right,Upward,Back and stop commands.\\
This speech command recognition model for a voice bot is based on concepts of Convolution, LSTM and Attention and is derived from \textbf{\textit{"A neural attention model for speech command
recognition."}} by Douglas Coimbra de Andrade, Sabato Leo, Martin Loesener Da Silva Viana, Christoph Bernkopf on arXiv.




\end{frame}

\begin{frame}{Create Data}
\frametitle{Create Data}
\begin{enumerate}
 \item Set 16KHz as sampling rate
    \item Record 80 utterances of each command.
    \item Trim each utterance to one second.
    \item Save samples of each command in different folders\\
        Data/forward\\
        Data/back\\
        Data/left\\
        Data/right\\
        Data/stop
\end{enumerate}

Used Audacity to do this.
\end{frame}

\begin{frame}
{Load Data}
Load Data using numpy files.\\
Can also use other package like wavefile,
librosa etc.
\end{frame}


\begin{frame}
{Split Dataset}
Do a stratified split of the dataset into train and test
set with 20% as test samples.
Set a random seed for reproducing the split.
\end{frame}


\begin{frame}
{Augment Data}
Augment each audio sample by time shifting in 25000
length vectors filled with zeros.
Take steps of 500 to create 18 files per sample
\end{frame}


\begin{frame}
{Feature Extraction}
MFCCs are most prominent features used in audio processing.
Normalizing the MFCCs over the frequency axis is found to reduce effect of noise.\\
Kapre is a python package that provides layers for audio processing that are compatible with keras and utilize GPU for faster processing. Kapre provides us with a layer basically\\


\end{frame}


\begin{frame}
{Melspectrogram}
\textit{Melspectrogram (padding='same', sr=16000, n\_mels=39, n\_dft = 1024, power\_melgram=2.0, return\_decibel\_melgram=True, trainable\_fb=False, trainable\_kernel=False,  name='mel\_stft')}\\

\textbf{Arguments to the layer}\\
\textbf{padding:} Padding when convoluting\\
\textbf{sr:} Sampling rate of audio provided\\
\textbf{n\_mels:} number of coefficients to return\\
\textbf{n\_dft:} width \\
\textbf{power\_melgram:} exponent to raise log-mel-amplitudes before taking DCT. Using power 2 is shown to increase performance by reducing effect of noise\\
\textbf{return\_decibel\_melgram:} If to return log over values\\
\textbf{trainable\_fb:} If filter bank trainable\\
\textbf{trainable\_kernel:} If the kernel is trainable
\end{frame}

\begin{frame}
{Building Model}
\textbf{Concept}
\begin{enumerate}
    \item Using Convolutional layers ahead of LSTM is shown to improve performance in several research papers.
    \item BatchNormalization layers are added to improve convergence rate.
    \item Using Bidirectional LSTM is optimal when complete input is available. But this increases the runtime two-fold.
    \item Final output sequence of LSTM layer is used to calculate importance of units in LSTM using a FC layer.
    \item Then take the dot product of unit importance and output sequences of LSTM to get Attention scores of each time step.
    \item Take the dot product of Attention scores and the output sequences of LSTM to get attention vector.
    \item Add an additional FC Layer and then to output Layer with SoftMax Activation.
\end{enumerate}
\end{frame}

\begin{frame}
{Hyper parameters}
\begin{itemize}
    \item \textbf{sparse\_categorical\_crossentropy} is used as \textbf{Loss} because only output which should be 1 is given instead of One Hot Encoding.
    \item \textbf{sparse\_categorical\_accuracy} is used as performance \textbf{Metric} for the above reason.
    \item \textbf{Adam} is used as \textbf{Optimizer}. Adam is adaptive learning rate optimization algorithm. This is shown to achieve a faster convergence because of having all the features of other optimization algorithms.
    \item Batch size of 15 is used
\end{itemize}
\end{frame}

\begin{frame}
{ Back Propagation}
\begin{itemize}
\item Back propagation is the algorithm used to calculate
the gradient of loss w.r.t all the parameters in the
neural network. 
\item Gradient of loss w.r.t input of the current layer or
function is back propagated as gradient of loss w.r.t
output of previous layer or function. Hence, the
name back propagation.
\end{itemize}
\end{frame}

\begin{frame}
{Testing}
\begin{enumerate}
    \item Augment the test set same as training set.
    \item Extract MFCCs using same method as training set
    \item Test set is passed as validation set to fit method of model.
    \item The performance of model on test set is calculated after every epoch.
\end{enumerate}

\end{frame}

\begin{frame}
{Visualize Attention}
\begin{enumerate}
    \item Now build a sub model from the trained model. Take same input layer but add ‘AttentionSoftmax’ layer as additional output layer.
    \item Pass MFCCs of test samples to predict method.
    \item Now plot log of Attention Scores and corresponding input vector before taking MFCCs on different axes.
    \end{enumerate}
\end{frame}
\begin{frame}
{References}
\begin{itemize}
 \item \textit{\textbf{A neural attention model for speech command
recognition.by Douglas Coimbra de Andrade, Sabato Leo, Martin Loesener Da Silva Viana, Christoph Bernkopf on arXiv.
arXiv:1808.08929v1 [eess.AS] 27 Aug 2018}}

 \item Github :https://github.com/PradeepMoturi/Speech-Command-Model/tree/master/Data/Pradeep_16
\end{itemize}
\end{frame}
\end{document}